\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[letterpaper, margin=1.5in]{geometry}
\usepackage{setspace}
\doublespacing

\usepackage[
backend=biber,
style=alphabetic,
sorting=ynt
]{biblatex}
\usepackage{tipa}
\usepackage{gb4e}
\addbibresource{refs.bib}


\title{\textbf{LIN 528 Final Project Report}\\Language Models: \textit{n}-grams and PCFGs}
\author{Derek Andersen and Joanne Chau}
\date{December, 2020}

\begin{document}

\maketitle

\section{Objective}

The objective of this project was to train, evaluate, and compare the efficiency of two different statistical language models: a trigram model and a probabilistic context-free grammar (PCFG). The underlying structure of these two types of models varies quite a bit, but they both hope to accomplish the same thing: to act as a representation (more accurately, an approximation) of a language (limited to the scope of a given corpus), and predict the likelihood of occurrence of some new unattested language data.

\subsection{Trigram model}
In the case of an \textit{n}-gram model, its purpose is to approximate the probability $P(w|h)$, or the probability of a word $w$ given some history $h$, where $h$ is a number of previous words equal to $n-1$. With our trigram model, $h=2$, so for a word being evaluated, its two-word history will be considered. It's important to note that the motivation behind the \textit{n}-gram model is to settle for the \textit{approximation} of the probability of some word given its recent history, since it isn't possible to calculate the exact probability of a word given its entire history. (jurafsky martin ch3pg3) 

\subsection{PCFG model}
In the case of a PCFG model, its purpose is to determine the most likely parse of a sentence, and output the probability of a sentence's most likely parse. It is trained on a training set of fully parsed trees, from which the model takes constructions it sees and constructs a grammar of Chomsky normal form (CNF) rules:
\begin{itemize}
    \item Start symbol (S)
    \item Non-terminals (NP, VP, etc.)
    \item Terminals (vocabulary items)
\end{itemize}

 
\section{Techniques and Tools}


\section{Results/Evaluation}



\section{Conclusion}


\printbibliography{}

\end{document}